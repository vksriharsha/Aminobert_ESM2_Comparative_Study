{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RGN2 Colab\n",
        "## Instructions\n",
        "1. Paste your protein sequence in the input field.\n",
        "2. Run the cells in the Colab individually with the play button on the left or via _Runtime_ > _Run all._\n",
        "3. The predicted protein structure will be downloaded after the final \"Refinement\" cell is executed."
      ],
      "metadata": {
        "id": "3SDCdyj7XneF"
      },
      "id": "3SDCdyj7XneF"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download RGN2 and Install Dependencies\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from IPython import get_ipython\n",
        "from IPython.utils import io\n",
        "\n",
        "WORKDIR = './rgn2'\n",
        "GIT_REPO = 'https://github.com/aqlaboratory/rgn2'\n",
        "ENV_CONFIG = os.path.join(WORKDIR, 'environment.yml')\n",
        "RGN2_PARAM_SOURCE_URL = 'https://huggingface.co/christinafl/rgn2'\n",
        "RGN2_PARAMS_DIR = os.path.join(WORKDIR, 'resources')\n",
        "RGN2_PARAM_RUN_DIR = os.path.join(RGN2_PARAMS_DIR, 'rgn2_runs')\n",
        "RGN2_RUN_DIR = os.path.join(WORKDIR, 'runs')\n",
        "\n",
        "AF2_GIT_REPO = 'https://github.com/deepmind/alphafold'\n",
        "AF2_SOURCE_URL = 'https://storage.googleapis.com/alphafold/alphafold_params_2022-03-02.tar'\n",
        "AF2_PARAMS_DIR = './alphafold/data/params'\n",
        "AF2_PARAMS_PATH = os.path.join(AF2_PARAMS_DIR, os.path.basename(AF2_SOURCE_URL))\n",
        "\n",
        "REFINER_DIR = os.path.join(WORKDIR, 'ter2pdb')\n",
        "REFINER_PATH = os.path.join(REFINER_DIR, 'ModRefiner-l.zip')\n",
        "REFINER_URL = 'https://zhanggroup.org/ModRefiner/ModRefiner-l.zip'\n",
        "\n",
        "try:\n",
        "  with io.capture_output() as captured:\n",
        "    %cd '/content'\n",
        "\n",
        "    # Different conda envs necessary due to conflicting dependencies.\n",
        "    %shell rm -rf /opt/conda\n",
        "    %shell wget -q -P /tmp \\\n",
        "      https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh \\\n",
        "        && bash /tmp/Miniconda3-latest-Linux-x86_64.sh -b -p /opt/conda \\\n",
        "        && rm /tmp/Miniconda3-latest-Linux-x86_64.sh\n",
        "    \n",
        "    PATH=%env PATH\n",
        "    %env PATH=/opt/conda/bin:{PATH}\n",
        "\n",
        "    CONDA_INIT = 'source /opt/conda/etc/profile.d/conda.sh && conda init'\n",
        "    RGN2_ENV_INIT = f'{CONDA_INIT} && conda activate rgn2'\n",
        "\n",
        "    # Download RGN2.\n",
        "    %shell rm -rf {WORKDIR}\n",
        "    %shell git clone {GIT_REPO} {WORKDIR}\n",
        "    %shell {CONDA_INIT} && conda env create -f {ENV_CONFIG}\n",
        "\n",
        "    # Download AF2 for AF2Rank-based refinement.\n",
        "    AF2_ENV_INIT = f'{CONDA_INIT} && conda activate af2'\n",
        "\n",
        "    %shell rm -rf alphafold\n",
        "    %shell git clone --branch main {AF2_GIT_REPO} alphafold\n",
        "    %shell {CONDA_INIT} && conda create -y -q --name af2 python=3.7\n",
        "    %shell {AF2_ENV_INIT} && pip install -r ./alphafold/requirements.txt\n",
        "    %shell {AF2_ENV_INIT} && pip install --no-dependencies ./alphafold\n",
        "    %shell {AF2_ENV_INIT} && pip install --upgrade jax==0.3.17 \\\n",
        "      jaxlib==0.3.15+cuda11.cudnn805 \\\n",
        "      -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "    \n",
        "    %shell mkdir --parents \"{AF2_PARAMS_DIR}\"\n",
        "    %shell wget -O \"{AF2_PARAMS_PATH}\" \"{AF2_SOURCE_URL}\"\n",
        "    %shell tar --extract --verbose --file=\"{AF2_PARAMS_PATH}\" \\\n",
        "      --directory=\"{AF2_PARAMS_DIR}\" --preserve-permissions\n",
        "    %shell rm \"{AF2_PARAMS_PATH}\"\n",
        "\n",
        "    # Download AminoBERT/RGN2 weights.\n",
        "    %shell GIT_LFS_SKIP_SMUDGE=1 git clone \"{RGN2_PARAM_SOURCE_URL}\" \"{RGN2_PARAMS_DIR}\"\n",
        "    %shell cd {RGN2_PARAMS_DIR} && git lfs pull\n",
        "    %shell mv {RGN2_PARAM_RUN_DIR} {RGN2_RUN_DIR}\n",
        "\n",
        "    # Download Modrefiner to initialize all atoms from CA trace.\n",
        "    %shell wget -O {REFINER_PATH} {REFINER_URL}\n",
        "    %shell unzip -o {REFINER_PATH} -d {REFINER_DIR}\n",
        "    %shell rm {REFINER_PATH}\n",
        "\n",
        "except subprocess.CalledProcessError:\n",
        "  print(captured)\n",
        "  raise"
      ],
      "metadata": {
        "id": "_ds-a3EgRUsb"
      },
      "id": "_ds-a3EgRUsb",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Python Packages\n",
        "\n",
        "%cd '/content/rgn2'\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import hashlib\n",
        "import json\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from IPython.utils import io\n",
        "from google.colab import files\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "\n",
        "sys.path.append('/content/alphafold')\n",
        "from ter2pdb import ter2pdb"
      ],
      "metadata": {
        "id": "7GBilHivRmgP",
        "outputId": "983a80ad-f2f0-4811-ccb1-f446eff386ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7GBilHivRmgP",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rgn2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### Enter the amino acid sequence to fold ⬇️\n",
        "sequence = 'WWNFGSLLAVCLMTQILTGLGASFFFICIFLHIGRGLYWNTGVILLLTLMATAHFLLPFAIAGITIIHLKDILGLTLMLTPFLTLGGVLALAASVLILFLITLFWLLVANLLILTWGQMASLSYFTILLILF'  #@param {type:\"string\"}\n",
        "jobname = 'test' #@param {type:\"string\"}\n",
        "\n",
        "# Remove whitespace\n",
        "sequence = \"\".join(sequence.split()).upper()\n",
        "jobname = \"\".join(jobname.split())\n",
        "\n",
        "jobname = re.sub(r'\\W+', '', jobname)\n",
        "seq_hash = hashlib.blake2b(sequence.encode(), digest_size=3).hexdigest()\n",
        "seq_id = f'{jobname}_{seq_hash}'\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1023\n",
        "\n",
        "# Remove all whitespaces, tabs and end lines; upper-case\n",
        "sequence = sequence.translate(str.maketrans('', '', ' \\n\\t')).upper()\n",
        "aatypes = set('ACDEFGHIKLMNPQRSTVWY')  # 20 standard aatypes\n",
        "if not set(sequence).issubset(aatypes):\n",
        "  raise Exception(f'Input sequence contains non-amino acid letters: {set(sequence) - aatypes}. AlphaFold only supports 20 standard amino acids as inputs.')\n",
        "if len(sequence) > MAX_SEQUENCE_LENGTH:\n",
        "  raise Exception(f'Input sequence is too long: {len(sequence)} amino acids, while the maximum is {MAX_SEQUENCE_LENGTH}. Please use the full AlphaFold system for long sequences.')\n",
        "\n",
        "run_inputs = {'sequence': sequence, 'seq_id': seq_id}\n",
        "with open(\"run.json\", \"w\") as f:\n",
        "    json.dump(run_inputs, f)\n",
        "\n",
        "DATA_DIR = 'aminobert_output'\n",
        "RUN_DIR = 'runs/15106000'\n",
        "OUTPUT_DIR = 'output'\n",
        "REFINE_DIR = 'output/refine_model1'\n",
        "SEQ_PATH = os.path.join(DATA_DIR, f'{seq_id}.fa')\n",
        "TER_PATH = os.path.join(RUN_DIR, '1', 'outputsTesting', f'{seq_id}.tertiary')"
      ],
      "metadata": {
        "id": "_5YeBefARz0D"
      },
      "id": "_5YeBefARz0D",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d93c3e44",
      "metadata": {
        "id": "d93c3e44",
        "outputId": "64fdcab2-2b05-4f9c-d073-3d176e7a07f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change     /opt/conda/condabin/conda\n",
            "no change     /opt/conda/bin/conda\n",
            "no change     /opt/conda/bin/conda-env\n",
            "no change     /opt/conda/bin/activate\n",
            "no change     /opt/conda/bin/deactivate\n",
            "no change     /opt/conda/etc/profile.d/conda.sh\n",
            "no change     /opt/conda/etc/fish/conf.d/conda.fish\n",
            "no change     /opt/conda/shell/condabin/Conda.psm1\n",
            "no change     /opt/conda/shell/condabin/conda-hook.ps1\n",
            "no change     /opt/conda/lib/python3.9/site-packages/xontrib/conda.xsh\n",
            "no change     /opt/conda/etc/profile.d/conda.csh\n",
            "no change     /root/.bashrc\n",
            "No action taken.\n",
            "Sequences being removed due to length: 0\n",
            "Sequences being removed: [] []\n",
            "Featurizing input\n",
            "Writing numpy arrays\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /content/rgn2/aminobert/optimization.py:110: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/prediction.py:18: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fc3c0fb5f80>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "WARNING:tensorflow:From /opt/conda/envs/rgn2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/run_finetuning_and_prediction.py:331: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/modeling.py:174: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/modeling.py:415: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/modeling.py:497: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/modeling.py:678: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /opt/conda/envs/rgn2/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/modeling.py:281: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/run_finetuning_and_prediction.py:280: The name tf.accumulate_n is deprecated. Please use tf.math.accumulate_n instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/run_finetuning_and_prediction.py:315: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/run_finetuning_and_prediction.py:362: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/rgn2/aminobert/run_finetuning_and_prediction.py:377: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "WARNING:tensorflow:From /opt/conda/envs/rgn2/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2022-11-14 04:58:53.776027: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
            "2022-11-14 04:58:53.822847: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000165000 Hz\n",
            "2022-11-14 04:58:53.823060: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8ab1696c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-11-14 04:58:53.823147: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-11-14 04:58:53.837901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-11-14 04:58:54.057835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-14 04:58:54.058646: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8ab169340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-11-14 04:58:54.058677: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-11-14 04:58:54.059984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-14 04:58:54.060572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-11-14 04:58:54.066061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-11-14 04:58:54.206814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-11-14 04:58:54.266039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-11-14 04:58:54.284415: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-11-14 04:58:54.443755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-11-14 04:58:54.540090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-11-14 04:58:54.832050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-11-14 04:58:54.832286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-14 04:58:54.832969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-14 04:58:54.833541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-11-14 04:58:54.836477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-11-14 04:58:54.837810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-11-14 04:58:54.837851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-11-14 04:58:54.837862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-11-14 04:58:54.838130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-14 04:58:54.838805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-14 04:58:54.839358: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-11-14 04:58:54.839421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2022-11-14 04:59:00.005344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "WARNING:tensorflow:From /content/rgn2/data_processing/aminobert_postprocessing.py:165: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Generate AminoBERT Embeddings\n",
        "\n",
        "%%bash\n",
        "source /opt/conda/etc/profile.d/conda.sh && conda init\n",
        "conda activate rgn2\n",
        "python\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "sys.path.append(os.path.join(os.getcwd(), 'aminobert'))\n",
        "\n",
        "import shutil\n",
        "from aminobert.prediction import aminobert_predict_sequence\n",
        "from data_processing.aminobert_postprocessing import aminobert_postprocess\n",
        "\n",
        "DATA_DIR = 'aminobert_output'\n",
        "DATASET_NAME = '1'\n",
        "PREPEND_M = True\n",
        "AMINOBERT_CHKPT_DIR = 'resources/aminobert_checkpoint/AminoBERT_runs_v2_uniparc_dataset_v2_5-1024_fresh_start_model.ckpt-1100000'\n",
        "\n",
        "with open(\"run.json\", \"r\") as f:\n",
        "    run_inputs = json.load(f)\n",
        "\n",
        "# Remove old data since AminoBERT combines entire directory to create dataset.\n",
        "if os.path.exists(DATA_DIR):\n",
        "  shutil.rmtree(DATA_DIR)\n",
        "os.makedirs(DATA_DIR)\n",
        "\n",
        "aminobert_predict_sequence(seq=run_inputs['sequence'], header=run_inputs['seq_id'],\n",
        "                           prepend_m=PREPEND_M, checkpoint=AMINOBERT_CHKPT_DIR,\n",
        "                           data_dir=DATA_DIR)\n",
        "aminobert_postprocess(data_dir=DATA_DIR, dataset_name=DATASET_NAME, prepend_m=PREPEND_M)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run RGN2\n",
        "#@markdown This step generates the raw RGN2-predicted C-alpha trace.\n",
        "\n",
        "rgn2_env_init = 'source /opt/conda/etc/profile.d/conda.sh && conda init && conda activate rgn2'\n",
        "try:\n",
        "  with io.capture_output() as captured:\n",
        "    cmd = (f\"python rgn/protling.py {os.path.join(RUN_DIR, 'configuration')} \"\n",
        "           f\"-p -e 'weighted_testing' -a -g 0\")\n",
        "    %shell {rgn2_env_init} && {cmd}\n",
        "except subprocess.CalledProcessError:\n",
        "  print(captured)\n",
        "  raise\n",
        "\n",
        "print('Prediction completed!')"
      ],
      "metadata": {
        "id": "IJkrRgF3R63Q",
        "outputId": "bd096e17-abbb-4c4e-d519-65848c7eebb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IJkrRgF3R63Q",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Refinement and Structure Download\n",
        "#@markdown Once this cell has been executed, a PDB file with the refined\n",
        "#@markdown structure will be automatically downloaded to your computer.\n",
        "#@markdown **Note**: Notebook refinement pipeline is ~2x slower compared\n",
        "#@markdown to local execution.\n",
        "recycles = 1 #@param {type:\"integer\"}\n",
        "\n",
        "ter2pdb.run_ca_to_allatom(seq_path=SEQ_PATH, ter_path=TER_PATH,\n",
        "                          output_dir=OUTPUT_DIR, seq_id=seq_id)\n",
        "\n",
        "out_suffix = '_prediction'\n",
        "af2_env_init = 'source /opt/conda/etc/profile.d/conda.sh && conda init && conda activate af2'\n",
        "jax_env_vars = 'TF_FORCE_UNIFIED_MEMORY=1 XLA_PYTHON_CLIENT_MEM_FRACTION=2.0'\n",
        "cmd = (f\"{jax_env_vars} python ter2pdb/run_af2rank.py refine_model1 \"\n",
        "       f\"--target_list {seq_id} --af2_dir /content/alphafold/ \"\n",
        "       f\"--out_suffix {out_suffix} --seq_dir {Path(SEQ_PATH).parent} \"\n",
        "       f\"--pdb_dir {OUTPUT_DIR} --output_dir {OUTPUT_DIR} --deterministic \"\n",
        "       f\"--seq_replacement - --mask_sidechains_add_cb --model_num 1 \"\n",
        "       f\"--recycles {recycles}\")\n",
        "try:\n",
        "  with io.capture_output() as captured:\n",
        "    %shell {af2_env_init} && {cmd}\n",
        "except subprocess.CalledProcessError:\n",
        "  print(captured)\n",
        "  raise\n",
        "\n",
        "print('Refinement completed!')\n",
        "\n",
        "files.download(os.path.join(REFINE_DIR, f'{seq_id}{out_suffix}.pdb'))"
      ],
      "metadata": {
        "id": "I0A_TUORSukb",
        "outputId": "d90ba91e-fabc-48d4-91a1-213cbd46bf54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "I0A_TUORSukb",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refinement completed!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_243cf1f8-2a77-44e1-84e3-1f677b9ab283\", \"test_101451_prediction.pdb\", 82377)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}