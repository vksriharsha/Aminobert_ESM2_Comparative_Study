{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vksriharsha/Aminobert_ESM2_Comparative_Study/blob/main/src/Aminobert_ESM2_Comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M5U4p9JdmKag",
        "outputId": "b7daef2c-e256-4ebd-a5d9-d94a248b72e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fair-esm[esmfold] in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Collecting ml-collections\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.8.2-py3-none-any.whl (798 kB)\n",
            "\u001b[K     |████████████████████████████████| 798 kB 32.5 MB/s \n",
            "\u001b[?25hCollecting biopython\n",
            "  Downloading biopython-1.80-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 32.5 MB/s \n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 457 kB/s \n",
            "\u001b[?25hCollecting omegaconf\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting deepspeed==0.5.9\n",
            "  Downloading deepspeed-0.5.9.tar.gz (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fair-esm[esmfold]) (1.7.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from fair-esm[esmfold]) (0.1.7)\n",
            "Collecting hjson\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.5.9->fair-esm[esmfold]) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.5.9->fair-esm[esmfold]) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.5.9->fair-esm[esmfold]) (5.4.8)\n",
            "Collecting py-cpuinfo\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.5.9->fair-esm[esmfold]) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.5.9->fair-esm[esmfold]) (4.64.1)\n",
            "Collecting triton==1.0.0\n",
            "  Downloading triton-1.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2 MB 45.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from ml-collections->fair-esm[esmfold]) (1.3.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml-collections->fair-esm[esmfold]) (6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml-collections->fair-esm[esmfold]) (1.15.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections->fair-esm[esmfold]) (0.5.5)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deepspeed==0.5.9->fair-esm[esmfold]) (3.0.9)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 61.3 MB/s \n",
            "\u001b[?25hCollecting lightning-utilities==0.3.*\n",
            "  Downloading lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->fair-esm[esmfold]) (4.1.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->fair-esm[esmfold]) (2022.11.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->fair-esm[esmfold]) (2.9.1)\n",
            "Collecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (3.8.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (2.23.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (22.1.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (2.14.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (0.4.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (3.19.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (3.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (1.50.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->fair-esm[esmfold]) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning->fair-esm[esmfold]) (3.2.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->lightning-utilities==0.3.*->pytorch-lightning->fair-esm[esmfold]) (2.1.0)\n",
            "Building wheels for collected packages: deepspeed, ml-collections, antlr4-python3-runtime, fire\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.5.9-py3-none-any.whl size=524336 sha256=88defc48946a2ebb023868edeca05836565fcdcc3a07f13d4bbf6ccc2f89a03b\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/00/64/2aeb9e77c46196d95544ae3c384735c2a819c6f101992c76ab\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=b6fdd4d617dc234caf3007d9119236099edfea97c725ef23343e67847a4d24f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/da/64/33c926a1b10ff19791081b705879561b715a8341a856a3bbd2\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=03dcd0ec322d19f1a427f1a0c1fefcf3f2ef10722c561382041ce42e8d8a1b3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=dba481bde1cf9762759fe6203d3787860682e5dfd61939bf1cbbebc7eff6a874\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built deepspeed ml-collections antlr4-python3-runtime fire\n",
            "Installing collected packages: fire, triton, torchmetrics, py-cpuinfo, ninja, lightning-utilities, hjson, antlr4-python3-runtime, pytorch-lightning, omegaconf, ml-collections, einops, deepspeed, biopython\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 biopython-1.80 deepspeed-0.5.9 einops-0.6.0 fire-0.4.0 hjson-3.1.0 lightning-utilities-0.3.0 ml-collections-0.1.1 ninja-1.11.1 omegaconf-2.2.3 py-cpuinfo-9.0.0 pytorch-lightning-1.8.2 torchmetrics-0.10.3 triton-1.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Bio\n",
            "  Downloading bio-1.5.1-py3-none-any.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from Bio) (2.23.0)\n",
            "Requirement already satisfied: biopython>=1.79 in /usr/local/lib/python3.7/dist-packages (from Bio) (1.80)\n",
            "Collecting mygene\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Bio) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython>=1.79->Bio) (1.21.6)\n",
            "Collecting biothings-client>=0.2.6\n",
            "  Downloading biothings_client-0.2.6-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (3.0.4)\n",
            "Installing collected packages: biothings-client, mygene, Bio\n",
            "Successfully installed Bio-1.5.1 biothings-client-0.2.6 mygene-3.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (1.80)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dllogger@ git+https://github.com/NVIDIA/dllogger.git\n",
            "  Cloning https://github.com/NVIDIA/dllogger.git to /tmp/pip-install-k7x71tbb/dllogger_e61db787548d48fb8cc7e02bb9b0daf1\n",
            "  Running command git clone -q https://github.com/NVIDIA/dllogger.git /tmp/pip-install-k7x71tbb/dllogger_e61db787548d48fb8cc7e02bb9b0daf1\n",
            "Building wheels for collected packages: dllogger\n",
            "  Building wheel for dllogger (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dllogger: filename=DLLogger-1.0.0-py3-none-any.whl size=5670 sha256=8c20780013f8571e4842de2333bed295d5b47d893498415b5e5c9b741311d50d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oa4yzoh7/wheels/db/ba/1b/87515aba93adffc7caccc21c0e93f80b70a857188790ce0436\n",
            "Successfully built dllogger\n",
            "Installing collected packages: dllogger\n",
            "Successfully installed dllogger-1.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openfold@ git+https://github.com/aqlaboratory/openfold.git@4b41059694619831a7db195b7e0988fc4ff3a307\n",
            "  Cloning https://github.com/aqlaboratory/openfold.git (to revision 4b41059694619831a7db195b7e0988fc4ff3a307) to /tmp/pip-install-o1elxhwm/openfold_e3c98557544a49348d47f21011acd715\n",
            "  Running command git clone -q https://github.com/aqlaboratory/openfold.git /tmp/pip-install-o1elxhwm/openfold_e3c98557544a49348d47f21011acd715\n",
            "  Running command git rev-parse -q --verify 'sha^4b41059694619831a7db195b7e0988fc4ff3a307'\n",
            "  Running command git fetch -q https://github.com/aqlaboratory/openfold.git 4b41059694619831a7db195b7e0988fc4ff3a307\n",
            "  Running command git checkout -q 4b41059694619831a7db195b7e0988fc4ff3a307\n",
            "Building wheels for collected packages: openfold\n",
            "  Building wheel for openfold (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openfold: filename=openfold-1.0.0-cp37-cp37m-linux_x86_64.whl size=1303253 sha256=e924fc0d1a19347c3117fe101b4161e730193832c1e351a4159f483a10919b34\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/42/ed/ebd86b9e9ac5f4f54a69a6567531bfa12a641e43ead98ef1f7\n",
            "Successfully built openfold\n",
            "Installing collected packages: openfold\n",
            "Successfully installed openfold-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install fair-esm\n",
        "!pip install fair-esm[esmfold]\n",
        "!pip install Bio\n",
        "!pip install biopython\n",
        "# OpenFold and its remaining dependency\n",
        "!pip install 'dllogger @ git+https://github.com/NVIDIA/dllogger.git'\n",
        "!pip install 'openfold @ git+https://github.com/aqlaboratory/openfold.git@4b41059694619831a7db195b7e0988fc4ff3a307'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCtdfHxtfWNm",
        "outputId": "f82785f9-74d5-4c79-9590-46e1e3ba42db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import torch\n",
        "import esm\n",
        "import os\n",
        "import re\n",
        "from ctypes import sizeof\n",
        "from collections import OrderedDict \n",
        "import sys\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "wNnIORRpls4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing"
      ],
      "metadata": {
        "id": "L8U9GfijSFiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set folder path of the PDB files"
      ],
      "metadata": {
        "id": "4OpJwQseTSnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder Path\n",
        "path = r\"/content/drive/MyDrive/PDB\""
      ],
      "metadata": {
        "id": "2T-wvgxFTRAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to convert PDB to FASTA file"
      ],
      "metadata": {
        "id": "HSPOeuPfRIU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convertPDBtoFASTA(pdb_file):\n",
        "    aa3to1={\n",
        "       'ALA':'A', 'VAL':'V', 'PHE':'F', 'PRO':'P', 'MET':'M',\n",
        "       'ILE':'I', 'LEU':'L', 'ASP':'D', 'GLU':'E', 'LYS':'K',\n",
        "       'ARG':'R', 'SER':'S', 'THR':'T', 'TYR':'Y', 'HIS':'H',\n",
        "       'CYS':'C', 'ASN':'N', 'GLN':'Q', 'TRP':'W', 'GLY':'G',\n",
        "       'MSE':'M', 'UNK':'X',\n",
        "    }\n",
        "    \n",
        "    ca_pattern=re.compile(\"^ATOM\\s{2,6}\\d{1,5}\\s{2}CA\\s[\\sA]([A-Z]{3})\\s([\\s\\w])|^HETATM\\s{0,4}\\d   {1,5}\\s{2}CA\\s[\\sA](MSE)\\s([\\s\\w])\")\n",
        "\n",
        "    filename=os.path.basename(pdb_file).split('.')[0]\n",
        "    dirname=os.path.dirname(pdb_file)\n",
        "    chain_dict=dict()\n",
        "    chain_list=[]\n",
        "\n",
        "    fp=open(pdb_file,'rU')\n",
        "    for line in fp.read().splitlines():\n",
        "        if line.startswith(\"ENDMDL\"):\n",
        "            break\n",
        "        match_list=ca_pattern.findall(line)\n",
        "        if match_list:\n",
        "            resn=match_list[0][0]+match_list[0][2]\n",
        "            chain=match_list[0][1]+match_list[0][3]\n",
        "            if chain in chain_dict:\n",
        "                chain_dict[chain]+=aa3to1[resn]\n",
        "            else:\n",
        "                chain_dict[chain]=aa3to1[resn]\n",
        "                chain_list.append(chain)\n",
        "    fp.close()\n",
        "\n",
        "    for chain in chain_list:\n",
        "\n",
        "      if not os.path.exists(dirname+\"/output/\"+filename+\"/\"):\n",
        "        os.makedirs(os.path.dirname(dirname+\"/output/\"+filename+\"/\"))\n",
        "\n",
        "      fasta_file = open(dirname+\"/output/\"+filename+\"/\"+filename+\".fasta\", \"a\")\n",
        "      fasta_file.write('>%s:%s\\n%s\\n'%(filename,chain,chain_dict[chain]))\n",
        "      fasta_file.close()\n",
        "      shutil.copy(dirname+\"/\"+filename+\".pdb\", dirname+\"/output/\"+filename+\"/\"+filename+\".pdb\")\n"
      ],
      "metadata": {
        "id": "a4rNDMJpCQON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting all PDB files to FASTA"
      ],
      "metadata": {
        "id": "lZuflrFORSAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Module\n",
        "import os\n",
        "\n",
        "# Change the directory\n",
        "os.chdir(path)\n",
        "\n",
        "# Read text File\n",
        "def read_text_file(file_path):\n",
        "\twith open(file_path, 'r') as f:\n",
        "\t\tprint(f.read())\n",
        "\n",
        "\n",
        "# iterate through all file\n",
        "\n",
        "print(\"Converting PDB files to FASTA files and writing to:\"+ path + \"/output\" )\n",
        "for file in tqdm(os.listdir()):\n",
        "\t# Check whether file is in text format or not\n",
        "\tif file.endswith(\".pdb\"):\n",
        "\t\tfile_path = f\"{path}/{file}\"\n",
        "\t\tconvertPDBtoFASTA(file_path)\n",
        "\t\n",
        "\n",
        "print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI0LZJVRCbQs",
        "outputId": "ebd01fbc-ceac-43ce-d02e-98612f031d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting PDB files to FASTA files and writing to:/content/drive/MyDrive/PDB/output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/861 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: 'U' mode is deprecated\n",
            "100%|██████████| 861/861 [04:37<00:00,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to get all second sequences in FASTA files"
      ],
      "metadata": {
        "id": "puMI-MgcRVgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_second_line(file):\n",
        "\twith open(file, 'r') as f:\n",
        "\t\treturn f.readlines()[1]\n"
      ],
      "metadata": {
        "id": "-P_aZfB-BtK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = path+\"/output\"\n",
        "\n",
        "# Change the directory\n",
        "os.chdir(path)\n",
        "\n",
        "# Read text File\n",
        "def read_text_file(file_path):\n",
        "\twith open(file_path, 'r') as f:\n",
        "\t\tprint(f.read())\n",
        "\n",
        "\n",
        "# iterate through all file\n",
        "ff=[]\n",
        "all_folders = os.listdir()\n",
        "\n",
        "print(\"Extracting the second sequence in all fasta files...\")\n",
        "for folder in tqdm(all_folders):\n",
        "\tos.chdir(path+\"/\"+folder)\n",
        "\tfor file in os.listdir():\n",
        "\t\tif file.endswith(\".fasta\"):\n",
        "\t\t\tfile_path = f\"{path}/{folder}/{file}\"\n",
        "\t\t\tff.append((file,get_second_line(file_path)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzYhwmx3jWeB",
        "outputId": "2de18a3f-78f6-437b-9687-0332216579fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting the second sequence in all fasta files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 430/430 [00:00<00:00, 625.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ESM-2"
      ],
      "metadata": {
        "id": "Kys5HTgpSBGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load ESM-2 pretrained model"
      ],
      "metadata": {
        "id": "J09EYhmvR8k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "batch_converter = alphabet.get_batch_converter()"
      ],
      "metadata": {
        "id": "PZdezMlXQuK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828e6ec1-8389-4259-e446-9854da8f09c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *** For Google Colab: Limiting number of proteins to 10\n",
        "\n",
        "Due to memory constraints"
      ],
      "metadata": {
        "id": "s9qhiF95UBGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ff = ff[0:3]\n",
        "\n",
        "ff"
      ],
      "metadata": {
        "id": "9SrWwkQCUAQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4e8c25-bdf3-4409-88c2-26ac7d1de53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2a06_bundle.fasta',\n",
              "  'WWNFGSLLGICLILQILTGLFLAIRYMHANGASMFFICLYMHVGRGLYTWNIGVILLLTVMATAFMGYFAFHFILPFIIMAIAMVHLIKDILGALLLILALMLLVLFALGGVLALAFSILILALIPLLSQCLFWALVADLLTLTWIGGITIGQLASVLYFLLILVLMPT\\n'),\n",
              " ('2a65_bundle.fasta',\n",
              "  'GLILAMAGNAVGLGNFLRFPMIPYIIAFLLVGIPLMWIEWAKILGVFGLWIPLVVAIYYVYIESWTLGFAIKFLVFAYIVFLITMFINVSILIRIERFAKIAMPTLFILAVFLVIRGVWIAAVGQIFFTLSLGFGAIITYLSGLTAATLNEKAEVILGGSILGFLWFFLLFFAGLTSSIAIMQPMIAFLAVLWTAAIVFFSAHLVMFLLDEMDFWAGTIGVVFFGLTELIIFFWIPRIYYYVMRYITPAFLAVLLVVWARWITRFYIIGLFLFLTFLVF\\n'),\n",
              " ('2b2f_bundle.fasta',\n",
              "  'ASTALVMLMVPGVGFFYAIALSFISLIITVLLWIFYGYSVSMYQMMFAAVTIAILTSAISSFILLSALWLTFVYAPFAHWLFAGGMVVHISSGFAALAVAMTLTLIGAALLWFGWFGFNGGSVVVTNTSAAVAGFVWMVIGWILGIVSGAIAGLAAITPAAKGAIVIGLVAGIVCYLAMDFRSLDAWAIHGIGGLWGSVAVGILLIAVASTTAYAFLVTLILAKAVDAAV\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate ESM-2 embeddings"
      ],
      "metadata": {
        "id": "aF1_8_lxsViZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import e\n",
        "print(\"Generating protein embeddings using ESM-2...\")\n",
        "for tuple in tqdm(ff):\n",
        "  data = [tuple]\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
        "  token_representations = results[\"representations\"][33]\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  \n",
        "  # file = open(path+\"/\"+data[0][0].split(\".\")[0]+\"/\"+data[0][0].split(\".\")[0]+\"_esm2.txt\", \"w+\")\n",
        "  if len(sequence_representations)< 2:\n",
        "    # torch.save(sequence_representations[0], path+\"/\"+data[0][0].split(\".\")[0]+\"/\"+data[0][0].split(\".\")[0]+\"_esm2.txt\")\n",
        "    np.savetxt(path+\"/\"+data[0][0].split(\".\")[0]+\"/\"+data[0][0].split(\".\")[0]+\"_esm2.txt\", torch.Tensor(sequence_representations[0]).numpy())\n",
        "    # content = str(sequence_representations[0])\n",
        "    # file.write(content)\n",
        "    # file.close()\n",
        "  else:\n",
        "    print(\"more than one representations\")\n",
        "  # Saving the array in a text file\n",
        "  # content = str(sequence_representations)\n",
        "  # file.write(content)\n",
        "  # file.close()\n",
        "\n",
        "\n",
        "# # Look at the unsupervised self-attention map contact predictions\n",
        "# import matplotlib.pyplot as plt\n",
        "# for (_, seq), tokens_len, attention_contacts in zip(ff, batch_lens, results[\"contacts\"]):\n",
        "#     plt.matshow(attention_contacts[: tokens_len, : tokens_len])\n",
        "#     plt.title(seq)\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "z34KCqz5p8aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57598c06-e653-47f4-8886-6060bf539bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating protein embeddings using ESM-2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:16<00:00,  5.61s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_representations"
      ],
      "metadata": {
        "id": "B0OvCZc9rS8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75546926-f75e-4c3d-ae55-6f88cdf1da60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([ 0.0435, -0.0686,  0.0389,  ...,  0.0573, -0.0584, -0.1091]),\n",
              " tensor([ 0.0514, -0.0141, -0.0357,  ...,  0.0535, -0.0585, -0.0356]),\n",
              " tensor([-0.0232, -0.0100,  0.0172,  ...,  0.0560, -0.0582, -0.0600])]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-sb8IMSnqccg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}